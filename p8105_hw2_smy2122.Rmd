---
title: "Homework 2"
author: "Sarah Younes"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options("scipen" = 1000)
```

As always, I will begin by loading the tidyverse, and I will additionally load `readxl` for Problem 2.

```{r tidyverse, message = FALSE}
library(tidyverse)
library(readxl)
```

# Problem 1

First, I will clean the data in pols-month.csv.

```{r pols_month_df}
pols_month_df =
  read.csv("./Data/fivethirtyeight_data/pols-month.csv") |>
  separate(mon, into = c("year", "month", "day"), sep = "-") |>
  mutate(
     month = replace(month, month == "01", "Jan"),
     month = replace(month, month == "02", "Feb"),
     month = replace(month, month == "03", "Mar"),
     month = replace(month, month == "04", "Apr"),
     month = replace(month, month == "05", "May"),
     month = replace(month, month == "06", "Jun"),
     month = replace(month, month == "07", "Jul"),
     month = replace(month, month == "08", "Aug"),
     month = replace(month, month == "09", "Sep"),
     month = replace(month, month == "10", "Oct"),
     month = replace(month, month == "11", "Nov"),
     month = replace(month, month == "12", "Dec")
  ) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  mutate(
    year = as.integer(year)
  ) |>
  select(year, month, everything(), -day, -starts_with("prez"))
```
    
Second, I will clean the data in snp.csv.

```{r snp_df}
snp_df =
  read.csv("./Data/fivethirtyeight_data/snp.csv") |>
  separate(date, into = c("month", "day", "year"), sep = "/") |>
  mutate(
     month = replace(month, month == "1", "Jan"),
     month = replace(month, month == "2", "Feb"),
     month = replace(month, month == "3", "Mar"),
     month = replace(month, month == "4", "Apr"),
     month = replace(month, month == "5", "May"),
     month = replace(month, month == "6", "Jun"),
     month = replace(month, month == "7", "Jul"),
     month = replace(month, month == "8", "Aug"),
     month = replace(month, month == "9", "Sep"),
     month = replace(month, month == "10", "Oct"),
     month = replace(month, month == "11", "Nov"),
     month = replace(month, month == "12", "Dec")
  ) |>
  mutate(
    year = as.integer(year)
  ) |>
  select(year, month, close)
```
   
Third, I will tidy the data in unemployment.csv.

```{r unemployment_df}
unemployment_df =
  read.csv("./Data/fivethirtyeight_data/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemployment"
  ) |>
  mutate(month = str_to_title(month))
```

Now, I will join the three datasets into a single data frame.

```{r merge problem 1}
problem_1_df =
  left_join(pols_month_df, snp_df) |>
  left_join(x = _, y = unemployment_df)
```

# Problem 2

First, I will load the `readxl` package and import and clean the Mr. Trash Wheel dataset. Data cleaning for this dataset involves setting missing values, cleaning the variable names, renaming two existing variables, creating two new variables, and changing the column type for one existing variable.

```{r mr_trash_wheel_df}
mr_trash_wheel_df =
  read_excel(
    "./Data/trash_wheel_data/202207 Trash Wheel Collection Data.xlsx",
    sheet = 1,
    range = "A2:M549",
    na = "") |>
  janitor::clean_names() |>
  rename(
    weight = weight_tons,
    volume = volume_cubic_yards) |>
  mutate(
    homes_powered = (weight*500)/30
  ) |>
  mutate(
    trash_wheel = "mr trash wheel"
  ) |>
  mutate(
    year = as.integer(year)
  )
```

Second, I will import and clean the Professor Trash Wheel dataset. Data cleaning for this dataset involves setting missing values, cleaning the variable names, renaming two existing variables, and creating two new variables.

```{r prof_trash_wheel_df}
prof_trash_wheel_df =
  read_excel(
    "./Data/trash_wheel_data/202207 Trash Wheel Collection Data.xlsx",
    sheet = 2,
    range = "A2:L96",
    na = "") |>
  janitor::clean_names() |>
  rename(
    weight = weight_tons,
    volume = volume_cubic_yards) |>
  mutate(
    homes_powered = (weight*500)/30
  ) |>
  mutate(
    trash_wheel = "professor trash wheel"
  )
```

Third, I will import and clean the Professor Trash Wheel dataset. Data cleaning for this dataset involves setting missing values, cleaning the variable names, renaming two existing variables, and creating two new variables.

```{r gwynnda_trash_wheel_df}
gwynnda_trash_wheel_df =
  read_excel(
    "./Data/trash_wheel_data/202207 Trash Wheel Collection Data.xlsx",
    sheet = 4,
    range = "A2:J108",
    na = "") |>
  janitor::clean_names() |>
  rename(
    weight = weight_tons,
    volume = volume_cubic_yards) |>
  mutate(
    homes_powered = (weight*500)/30
  ) |>
  mutate(
    trash_wheel = "gwynnda trash wheel"
  )
```

Finally, I will merge all three datasets by using `bind_rows` instead of another join or merge type because most of the column names are consistent across datasets and rows just need to be added to create one horizontally-longer dataset.

```{r merge problem 2}
merged_trash_wheel_df =
  bind_rows(mr_trash_wheel_df, prof_trash_wheel_df, gwynnda_trash_wheel_df) |>
  select(trash_wheel, everything())
```

Each dataset describes trash collected by different trash wheels around Baltimore, Maryland from May 2014 to July 2022. The first dataset in this problem, Mr. Trash Wheel, contains `r nrow(mr_trash_wheel_df)` rows or observations and `r ncol(mr_trash_wheel_df)` columns. The second dataset in this problem, Professor Trash Wheel, contains `r nrow(prof_trash_wheel_df)` rows or observations and `r ncol(prof_trash_wheel_df)` columns. The third dataset in this problem, Gwynnda Trash Wheel, contains `r nrow(gwynnda_trash_wheel_df)` rows or observations and `r ncol(gwynnda_trash_wheel_df)` columns. Each row represents one different dumpster that the trash wheel picks up trash from; thus, Mr. Trash Wheel collects trash from the most dumpsters, followed by Gwynnda Trash Wheel and Professor Trash Wheel. The columns for each dataset tell us the `date` of trash collection, `weight` (in tons) and `volume` (in cubic yards) of that dumpster's trash, and different types of trash that the trash wheels have collected, such as `plastic bottles` and `grocery bags`. The merged dataset with all three trash wheels contains `r nrow(merged_trash_wheel_df)` rows or observations and `r ncol(merged_trash_wheel_df)` columns. Altogether, the three trash wheels collected `r sum(pull(merged_trash_wheel_df, weight)) |> round(2)` tons of trash and `r sum(pull(merged_trash_wheel_df, volume)) |> round(2)` cubic pounds of trash. Professor Trash Wheel alone collected `r filter(merged_trash_wheel_df, trash_wheel == "professor trash wheel") |> pull(weight) |> sum() |> round(2)` tons of trash. Altogether, the three trash wheels collected `r filter(merged_trash_wheel_df, month == "July", year == 2021) |> pull(cigarette_butts) |> sum() |> round(2)` cigarette butts in July of 2021, while Gwynnda Trash Wheel alone collected `r filter(merged_trash_wheel_df, month == "July", year == 2021, trash_wheel == "gwynnda trash wheel") |> pull(cigarette_butts) |> sum() |> round(2)` cigarette butts in July of 2021. Additionally, the three trash wheels collectively powered `r sum(pull(merged_trash_wheel_df, homes_powered)) |> round(2)` homes.

# Problem 3

First, I will import and clean the dataset of baseline demographics. Data cleaning for this dataset first involves cleaning the variable names, renaming an existing variable, and recoding two existing variables, and removing participants who do not meet the inclusion criteria.

```{r demographics_dfs}
demographics_recruited_df =
  read.csv(
    "./Data/data_mci/MCI_baseline.csv",
    skip = 1,
    na = "."
  ) |>
  janitor::clean_names() |>
  rename(
    baseline_age = current_age) |>
  mutate(
    sex =
      case_match(
        sex,
        0 ~ "male",
        1 ~ "female"),
        sex = as.factor(sex)
  ) |>
  mutate(
    apoe4 =
      case_match(
        apoe4,
        0 ~ "non carrier",
        1 ~ "carrier"),
        apoe4 = as.factor(apoe4)
  )

demographics_qualified_df =
  demographics_recruited_df |>
  filter(is.na(age_at_onset))
```

The above dataset includes basic demographic information of potential and actual participants for the observational study. It includes only 6 variables collected at baseline: participants' study ID, current age, sex, years of education, whether they carry the APOE4 variant, and age at onset of Mild Cognitive Impairment (MCI). Arguably the most important use of this dataset is its ability to screen whether potential participants qualify of the study, since one of the major inclusion criteria is that participants must be free of MCI at baseline. Therefore, one of the most important steps in the import process was setting potential participants who did not have a baseline age at onset for MCI as missing (NA) and filtering out participants who had an age at onset for MCI (in other words, participants without an NA for age at onset). Before this process, a total of `r nrow(demographics_recruited_df)` participants were recruited for the observational study. However, only `r nrow(demographics_qualified_df)` participants qualified for the study since `r nrow(demographics_recruited_df) - nrow(demographics_qualified_df)` potential participants were discovered to have MCI at baseline. Among those who qualified, the average baseline age of participants was `r mean(pull(demographics_qualified_df, baseline_age))` years old.

The proportion of women in the study who are APOE4 carriers is `r nrow(demographics_qualified_df, apoe4 == "carrier", sex == "female")`.

Second, I will import and clean the dataset of longitudinally observed biomarker values.

```{r amyloid_df}
amyloid_df =
  read.csv(
    "./Data/data_mci/mci_amyloid.csv",
    skip = 1,
    na = c("NA", "Na")
  ) |>
  janitor::clean_names() |>
  rename(id = study_id)
```

Now, I will check if some participants appear in only the baseline or amyloid datasets by doing an anti-join.

```{r anti-join}
anti_join(demographics_qualified_df, amyloid_df, by = "id")
```

The output of the anti-join showed that 5 participants (IDs: 92, 179, 304, 389, 412) were in either the baseline or amyloid dataset but not both. Upon further investigation, all of these participants were in the baseline dataset but not the amyloid dataset, so it is likely that participants were recruited for and qualified for the study but ultimately decided not to continue participation in the study and withdraw.

Now, I will combine the baseline and amyloid datasets so that only participants who appear in both datasets are retained.

```{r merge problem 3}
merged_alzheimers_df =
  left_join(amyloid_df, demographics_qualified_df, by = "id")
```

Finally, I will export the resulting merged dataset as a CSV to my data directory.

```{r export}
write_csv(merged_alzheimers_df, "alzheimers_dataset.csv")
```