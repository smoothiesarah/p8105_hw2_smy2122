Homework 2
================
Sarah Younes

As always, I will begin by loading the tidyverse, and I will
additionally load `readxl` for Problem 2.

``` r
library(tidyverse)
library(readxl)
```

# Problem 1

First, I will clean the data in pols-month.csv.

``` r
pols_df =
  read.csv("./Data/fivethirtyeight_data/pols-month.csv") |>
  separate(mon, into = c("year", "month", "day"), sep = "-") |>
  mutate(
     month = replace(month, month == "01", "Jan"),
     month = replace(month, month == "02", "Feb"),
     month = replace(month, month == "03", "Mar"),
     month = replace(month, month == "04", "Apr"),
     month = replace(month, month == "05", "May"),
     month = replace(month, month == "06", "Jun"),
     month = replace(month, month == "07", "Jul"),
     month = replace(month, month == "08", "Aug"),
     month = replace(month, month == "09", "Sep"),
     month = replace(month, month == "10", "Oct"),
     month = replace(month, month == "11", "Nov"),
     month = replace(month, month == "12", "Dec")
  ) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  mutate(
    year = as.integer(year)
  ) |>
  select(year, month, everything(), -day, -starts_with("prez"))
```

Second, I will clean the data in snp.csv.

``` r
snp_df =
  read.csv("./Data/fivethirtyeight_data/snp.csv") |>
  separate(date, into = c("month", "day", "year"), sep = "/") |>
  mutate(
     month = replace(month, month == "1", "Jan"),
     month = replace(month, month == "2", "Feb"),
     month = replace(month, month == "3", "Mar"),
     month = replace(month, month == "4", "Apr"),
     month = replace(month, month == "5", "May"),
     month = replace(month, month == "6", "Jun"),
     month = replace(month, month == "7", "Jul"),
     month = replace(month, month == "8", "Aug"),
     month = replace(month, month == "9", "Sep"),
     month = replace(month, month == "10", "Oct"),
     month = replace(month, month == "11", "Nov"),
     month = replace(month, month == "12", "Dec")
  ) |>
  mutate(
    year = as.integer(year)
  ) |>
  select(year, month, close)
```

Third, I will tidy the data in unemployment.csv.

``` r
unemployment_df =
  read.csv("./Data/fivethirtyeight_data/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemployment"
  ) |>
  mutate(month = str_to_title(month))
```

Now, I will join the three datasets into a single data frame.

``` r
problem_1_df =
  left_join(pols_df, snp_df) |>
  left_join(x = _, y = unemployment_df)
```

# Problem 2

First, I will load the `readxl` package and import and clean the
Mr. Trash Wheel dataset. Data cleaning for this dataset involves setting
missing values, cleaning the variable names, renaming two existing
variables, creating two new variables, and changing the column type for
one existing variable.

``` r
mr_trash_wheel_df =
  read_excel(
    "./Data/trash_wheel_data/202309 Trash Wheel Collection Data.xlsx",
    sheet = 1,
    range = "A2:M549",
    na = "") |>
  janitor::clean_names() |>
  rename(
    weight = weight_tons,
    volume = volume_cubic_yards) |>
  mutate(
    homes_powered = (weight*500)/30
  ) |>
  mutate(
    trash_wheel = "mr trash wheel"
  ) |>
  mutate(
    year = as.integer(year)
  )
```

Second, I will import and clean the Professor Trash Wheel dataset. Data
cleaning for this dataset involves setting missing values, cleaning the
variable names, renaming two existing variables, and creating two new
variables.

``` r
prof_trash_wheel_df =
  read_excel(
    "./Data/trash_wheel_data/202309 Trash Wheel Collection Data.xlsx",
    sheet = 2,
    range = "A2:L96",
    na = "") |>
  janitor::clean_names() |>
  rename(
    weight = weight_tons,
    volume = volume_cubic_yards) |>
  mutate(
    homes_powered = (weight*500)/30
  ) |>
  mutate(
    trash_wheel = "professor trash wheel"
  )
```

Third, I will import and clean the Professor Trash Wheel dataset. Data
cleaning for this dataset involves setting missing values, cleaning the
variable names, renaming two existing variables, and creating two new
variables.

``` r
gwynnda_trash_wheel_df =
  read_excel(
    "./Data/trash_wheel_data/202309 Trash Wheel Collection Data.xlsx",
    sheet = 4,
    range = "A2:J108",
    na = "") |>
  janitor::clean_names() |>
  rename(
    weight = weight_tons,
    volume = volume_cubic_yards) |>
  mutate(
    homes_powered = (weight*500)/30
  ) |>
  mutate(
    trash_wheel = "gwynnda trash wheel"
  )
```

Finally, I will merge all three datasets by using `bind_rows` instead of
another join or merge type because most of the column names are
consistent across datasets and rows just need to be added to create one
horizontally-longer dataset.

``` r
merged_trash_wheel_df =
  bind_rows(mr_trash_wheel_df, prof_trash_wheel_df, gwynnda_trash_wheel_df) |>
  select(trash_wheel, everything())
```

Each dataset describes trash collected by different trash wheels around
Baltimore, Maryland from May 2014 to July 2022. The first dataset in
this problem, Mr. Trash Wheel, contains 547 observations and 15
variables. The second dataset in this problem, Professor Trash Wheel,
contains 94 observations and 14 variables. The third dataset in this
problem, Gwynnda Trash Wheel, contains 106 observations and 12
variables. Each row represents one different dumpster that the trash
wheel picks up trash from; thus, Mr. Trash Wheel collects trash from the
most dumpsters, followed by Gwynnda Trash Wheel and Professor Trash
Wheel. The columns for each dataset tell us the `date` of trash
collection, `weight` (in tons) and `volume` (in cubic yards) of that
dumpster’s trash, and different types of trash that the trash wheels
have collected, such as `plastic bottles` and `grocery bags`. The merged
dataset with all three trash wheels contains 747 observations and 15
variables. Altogether, the three trash wheels collected 2249.26 tons of
trash and 11331 cubic pounds of trash. Professor Trash Wheel alone
collected 190.12 tons of trash. Altogether, the three trash wheels
collected 45800 cigarette butts in July of 2021, while Gwynnda Trash
Wheel alone collected 16300 cigarette butts in July of 2021.
Additionally, the three trash wheels collectively powered 37487.67
homes.

# Problem 3

First, I will import and clean the dataset of baseline demographics.
Data cleaning for this dataset first involves cleaning the variable
names, renaming an existing variable, and recoding two existing
variables, and removing participants who do not meet the inclusion
criteria.

``` r
demographics_recruited_df =
  read.csv(
    "./Data/data_mci/MCI_baseline.csv",
    skip = 1,
    na = "."
  ) |>
  janitor::clean_names() |>
  rename(
    baseline_age = current_age) |>
  mutate(
    sex =
      case_match(
        sex,
        0 ~ "male",
        1 ~ "female"),
        sex = as.factor(sex)
  ) |>
  mutate(
    apoe4 =
      case_match(
        apoe4,
        0 ~ "non carrier",
        1 ~ "carrier"),
        apoe4 = as.factor(apoe4)
  )

demographics_qualified_df =
  demographics_recruited_df |>
  filter(is.na(age_at_onset))
```

The above dataset includes basic demographic information of potential
and actual participants for the observational study. It includes only 6
variables collected at baseline: participants’ study ID, current age,
sex, years of education, whether they carry the APOE4 variant, and age
at onset of Mild Cognitive Impairment (MCI). Arguably the most important
use of this dataset is its ability to screen whether potential
participants qualify of the study, since one of the major inclusion
criteria is that participants must be free of MCI at baseline.
Therefore, one of the most important steps in the import process was
setting potential participants who did not have a baseline age at onset
for MCI as missing (NA) and filtering out participants who had an age at
onset for MCI (in other words, participants without an NA for age at
onset). Before this process, a total of 483 participants were recruited
for the observational study. However, only 386 participants qualified
for the study since 97 potential participants were discovered to have
MCI at baseline. Among those who qualified, the average baseline age of
participants was 64.9049223 years old. 23.0769231% of women who
qualified for the study were carriers of the APOE4 gene.

Second, I will import and clean the dataset of longitudinally observed
biomarker values.

``` r
amyloid_df =
  read.csv(
    "./Data/data_mci/mci_amyloid.csv",
    skip = 1,
    na = c("NA", "Na")
  ) |>
  janitor::clean_names() |>
  rename(id = study_id)
```

Now, I will check if some participants appear in only the baseline or
amyloid datasets by doing an anti-join.

``` r
anti_join(demographics_qualified_df, amyloid_df, by = "id")
```

    ##    id baseline_age    sex education       apoe4 age_at_onset
    ## 1  92         68.6   male        20 non carrier           NA
    ## 2 179         68.1 female        16 non carrier           NA
    ## 3 304         63.8   male        16 non carrier           NA
    ## 4 389         59.3   male        16 non carrier           NA
    ## 5 412         67.0 female        16     carrier           NA

The output of the anti-join showed that 5 participants (IDs: 92, 179,
304, 389, 412) were in either the baseline or amyloid dataset but not
both. Upon further investigation, all of these participants were in the
baseline dataset but not the amyloid dataset, so it is likely that
participants were recruited for and qualified for the study but
ultimately decided not to continue participation in the study and
withdraw.

Now, I will combine the baseline and amyloid datasets so that only
participants who appear in both datasets are retained.

``` r
merged_alzheimers_df =
  left_join(amyloid_df, demographics_qualified_df, by = "id")
```

The merged dataset contains 487 rows or observations and 11 columns.

Finally, I will export the resulting merged dataset as a CSV to my data
directory.

``` r
write_csv(merged_alzheimers_df, "alzheimers_dataset.csv")
```
