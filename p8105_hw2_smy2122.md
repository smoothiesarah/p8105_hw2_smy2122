Homework 2
================
Sarah Younes

As always, I will begin by loading the tidyverse, and I will
additionally load `readxl` for Problem 2.

``` r
library(tidyverse)
library(readxl)
```

# Problem 1

First, I will clean the data in pols-month.csv.

``` r
pols_df =
  read.csv("./Data/fivethirtyeight_data/pols-month.csv") |>
  separate(mon, into = c("year", "month", "day"), sep = "-") |>
  mutate(
     month = replace(month, month == "01", "Jan"),
     month = replace(month, month == "02", "Feb"),
     month = replace(month, month == "03", "Mar"),
     month = replace(month, month == "04", "Apr"),
     month = replace(month, month == "05", "May"),
     month = replace(month, month == "06", "Jun"),
     month = replace(month, month == "07", "Jul"),
     month = replace(month, month == "08", "Aug"),
     month = replace(month, month == "09", "Sep"),
     month = replace(month, month == "10", "Oct"),
     month = replace(month, month == "11", "Nov"),
     month = replace(month, month == "12", "Dec")
  ) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  mutate(
    year = as.integer(year)
  ) |>
  select(year, month, everything(), -day, -starts_with("prez"))
```

Second, I will clean the data in snp.csv.

``` r
snp_df =
  read.csv("./Data/fivethirtyeight_data/snp.csv") |>
  separate(date, into = c("month", "day", "year"), sep = "/") |>
  mutate(
     month = replace(month, month == "1", "Jan"),
     month = replace(month, month == "2", "Feb"),
     month = replace(month, month == "3", "Mar"),
     month = replace(month, month == "4", "Apr"),
     month = replace(month, month == "5", "May"),
     month = replace(month, month == "6", "Jun"),
     month = replace(month, month == "7", "Jul"),
     month = replace(month, month == "8", "Aug"),
     month = replace(month, month == "9", "Sep"),
     month = replace(month, month == "10", "Oct"),
     month = replace(month, month == "11", "Nov"),
     month = replace(month, month == "12", "Dec")
  ) |>
  mutate(
    year = as.integer(year)
  ) |>
  select(year, month, close)
```

Third, I will tidy the data in unemployment.csv.

``` r
unemployment_df =
  read.csv("./Data/fivethirtyeight_data/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemployment"
  ) |>
  mutate(month = str_to_title(month))
```

Now, I will join the three datasets into a single data frame.

``` r
problem_1_df =
  left_join(pols_df, snp_df) |>
  left_join(x = _, y = unemployment_df)
```

# Problem 2

First, I will import and clean the Mr. Trash Wheel dataset. Data
cleaning for this dataset involves selecting the right range of data,
setting missing values, cleaning the variable names, renaming two
existing variables, creating two new variables, and changing the column
type for one existing variable.

``` r
mr_trash_wheel_df =
  read_excel(
    "./Data/trash_wheel_data/202309 Trash Wheel Collection Data.xlsx",
    sheet = 1,
    range = "A2:M549",
    na = "") |>
  janitor::clean_names() |>
  rename(
    weight = weight_tons,
    volume = volume_cubic_yards) |>
  mutate(
    homes_powered = (weight*500)/30
  ) |>
  mutate(
    trash_wheel = "mr trash wheel"
  ) |>
  mutate(
    year = as.integer(year)
  )
```

Second, I will import and clean the Professor Trash Wheel dataset. Data
cleaning for this dataset involves selecting the right range of data,
setting missing values, cleaning the variable names, renaming two
existing variables, and creating two new variables.

``` r
prof_trash_wheel_df =
  read_excel(
    "./Data/trash_wheel_data/202309 Trash Wheel Collection Data.xlsx",
    sheet = 2,
    range = "A2:L96",
    na = "") |>
  janitor::clean_names() |>
  rename(
    weight = weight_tons,
    volume = volume_cubic_yards) |>
  mutate(
    homes_powered = (weight*500)/30
  ) |>
  mutate(
    trash_wheel = "professor trash wheel"
  )
```

Third, I will import and clean the Professor Trash Wheel dataset. Data
cleaning for this dataset involves selecting the right range of data,
setting missing values, cleaning the variable names, renaming two
existing variables, and creating two new variables.

``` r
gwynnda_trash_wheel_df =
  read_excel(
    "./Data/trash_wheel_data/202309 Trash Wheel Collection Data.xlsx",
    sheet = 4,
    range = "A2:J108",
    na = "") |>
  janitor::clean_names() |>
  rename(
    weight = weight_tons,
    volume = volume_cubic_yards) |>
  mutate(
    homes_powered = (weight*500)/30
  ) |>
  mutate(
    trash_wheel = "gwynnda trash wheel"
  )
```

Finally, I will merge all three datasets by using `bind_rows` instead of
another join or merge type because most of the column names are
consistent across datasets and rows just need to be added to create one
horizontally-longer dataset.

``` r
merged_trash_wheel_df =
  bind_rows(mr_trash_wheel_df, prof_trash_wheel_df, gwynnda_trash_wheel_df) |>
  select(trash_wheel, everything())
```

Each dataset describes trash collected by different trash wheels around
Baltimore, Maryland from May 2014 to July 2022. The first dataset in
this problem, Mr. Trash Wheel, contains 547 observations and 15
variables. The second dataset in this problem, Professor Trash Wheel,
contains 94 observations and 14 variables. The third dataset in this
problem, Gwynnda Trash Wheel, contains 106 observations and 12
variables. Each row represents one different dumpster that the trash
wheel picks up trash from; thus, Mr. Trash Wheel collects trash from the
most dumpsters, followed by Gwynnda Trash Wheel and Professor Trash
Wheel. The columns for each dataset tell us the `date` of trash
collection, `weight` (in tons) and `volume` (in cubic yards) of that
dumpster’s trash, and different types of trash that the trash wheels
have collected, such as `plastic bottles` and `grocery bags`. The merged
dataset with all three trash wheels contains 747 observations and 15
variables. Altogether, the three trash wheels collected 2249.26 tons of
trash and 11331 cubic pounds of trash. Professor Trash Wheel alone
collected 190.12 tons of trash. Altogether, the three trash wheels
collected 45800 cigarette butts in July of 2021, while Gwynnda Trash
Wheel alone collected 16300 cigarette butts in July of 2021.
Additionally, the three trash wheels collectively powered 37487.67
homes.

# Problem 3

First, I will import and clean the dataset of baseline demographics.
Data cleaning for this dataset first involves skipping the first row of
non-data, setting missing values, cleaning the variable names, renaming
an existing variable, and recoding two existing variables, and removing
participants who do not meet the inclusion criteria.

``` r
demographics_df =
  read.csv(
    "./Data/data_mci/MCI_baseline.csv",
    skip = 1,
    na = "."
  ) |>
  janitor::clean_names() |>
  rename(
    baseline_age = current_age) |>
  mutate(
    sex =
      case_match(
        sex,
        0 ~ "male",
        1 ~ "female"),
        sex = as.factor(sex)
  ) |>
  mutate(
    apoe4 =
      case_match(
        apoe4,
        0 ~ "non carrier",
        1 ~ "carrier"),
        apoe4 = as.factor(apoe4)
  ) |>
  filter(baseline_age < age_at_onset | is.na(age_at_onset))
```

The above dataset includes basic demographic information of potential
and actual participants for the observational study. It includes only 6
variables collected at baseline: participants’ study ID, current age,
sex, years of education, whether they carry the APOE4 variant, and age
at onset of Mild Cognitive Impairment (MCI). Arguably the most important
use of this dataset is its ability to screen whether potential
participants qualify of the study, since one of the major inclusion
criteria is that participants must be free of MCI at baseline.
Therefore, one of the most important steps in the import process was
setting potential participants who did not have an age at onset for MCI
as missing or NA and filtering out participants who had an age at onset
for MCI that predated the baseline study.

After this process, a total of 479 participants were recruited or
qualified for the observational study. Among these, 93 participants
developed MCI during the study. The average baseline age of participants
who qualified was 65.03 years old. Additionally, 30.11% of women who
qualified for the study were carriers of the APOE4 gene.

Second, I will import and clean the dataset of longitudinally observed
biomarker values. Data cleaning for this dataset involves skipping the
first row of non-data, setting missing values, cleaning the variable
names, tidying the data into a longer table, and clarifying category
labels, and renaming an existing variable.

``` r
amyloid_df =
  read.csv(
    "./Data/data_mci/mci_amyloid.csv",
    skip = 1,
    na = c("NA", "Na")
  ) |>
  janitor::clean_names() |>
  pivot_longer(
    baseline:time_8,
    names_to = "year",
    values_to = "biomarker_ratio"
  ) |>
  mutate(
    year = replace(year, year == "baseline", "0"),
    year = replace(year, year == "time_2", "2"),
    year = replace(year, year == "time_4", "4"),
    year = replace(year, year == "time_6", "6"),
    year = replace(year, year == "time_8", "8")
  ) |>
  rename(id = study_id)
```

The amyloid dataset now consists of 3 columns instead of 6: one column
for the `study ID`, another for the `time period (in years)` that is
being measured, and a final column for the `biomarker ratio value` at
each time period.

Now, I will check if some participants appear in only the baseline or
amyloid datasets by doing an anti-join.

``` r
anti_join(demographics_df, amyloid_df, by = "id") |>
  distinct(id) |> 
  nrow()
```

    ## [1] 8

``` r
anti_join(amyloid_df, demographics_df, by = "id") |>
  distinct(id) |> 
  nrow()
```

    ## [1] 16

The output of the first anti-join showed that 8 participants were in the
baseline demographics dataset but not the amyloid dataset. The output of
the second anti-join showed that 16 different participants were int the
amyloid dataset but not the baseline demographics dataset.

Now, I will combine the baseline and amyloid datasets so that only
participants who appear in both datasets are retained by using an inner
join.

``` r
merged_alzheimers_df =
  inner_join(amyloid_df, demographics_df, by = "id")
```

The merged dataset contains 2355 observations and 8 variables. There are
471 total participants in this dataset, with multiple rows or
observations per participant to reflect the different follow-up times
over the 8-year study period. The average biomarker ratio value was
0.11.

Finally, I will export the resulting merged dataset as a CSV to my data
directory.

``` r
write_csv(merged_alzheimers_df, "alzheimers_dataset.csv")
```
